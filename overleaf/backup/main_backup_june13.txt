\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{tabularx,lipsum,environ,amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{placeins}
\usepackage{xcolor}
\usepackage{amsthm}

\makeatletter

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newenvironment{hashtable}[1][]
  {\begin{tabular}[#1]{
     @{} 
     > {\small} r <{\normalsize~\rlap{\fbox{\strut~~}}$~~\rightarrow$~}
     @{} l @{}}}
  {\end{tabular}}
 

\newcommand{\problemtitle}[1]{\gdef\@problemtitle{#1}}% Store problem title
\newcommand{\probleminput}[1]{\gdef\@probleminput{#1}}% Store problem input
\newcommand{\problemquestion}[1]{\gdef\@problemquestion{#1}}% Store problem question
\NewEnviron{problem}{
  \problemtitle{}\probleminput{}\problemquestion{}% Default input is empty
  \BODY% Parse input
  \par\addvspace{.5\baselineskip}
  \noindent
  \begin{tabularx}{\textwidth}{@{\hspace{\parindent}} l X c}
    \multicolumn{2}{@{\hspace{\parindent}}l}{\@problemtitle} \\% Title
    \textbf{Input:} & \@probleminput \\% Input
    \textbf{Problem:} & \@problemquestion% Question
  \end{tabularx}
  \par\addvspace{.5\baselineskip}
}
\makeatother

\newcommand{\ml}[1]{\begingroup\color{blue}#1\endgroup}
\newcommand{\rk}[1]{\begingroup\color{red}#1\endgroup}

\title{Algorithm to find segmental duplications and losses}
%\author{r3za.kalhor }
\date{}

\begin{document}

\maketitle

\section{Problem}
Under Minimum Episode (ME) model that duplication events can affect gene in the same species but can't contain a gene and one of its descendants (is shown that the problem of finding the optimal reconciliation with minimum number of ME duplication is NP-hard and the complexity of proposed algorithm is $O((\delta/\lambda)^{d+1}.n)$, $\delta$ is cost of segmental duplication and $\lambda$ is cost of segmental loss).\\ So, what we want to do? is define an algorithm to find segmental dups and losses with better complexity under ME model (unrestricted ME?) or a scalable algorithm?\\



\begin{problem}
  \problemtitle{Segmental Reconciliation Algorithm}
  \probleminput{A set of gene trees $G'$, a species tree $S$, mapping $m$, cost of segmental duplication $\delta$ and cost of loss $\lambda$}
  \problemquestion{Inferring ME segmental duplications + losses events with minimum cost }
\end{problem}

\section{Preliminary notions}

[notations on trees, LCA, parent, define height of forest, define  ...]

\subsection{Reconciliations}
For given a set of gene trees $G'$ and a species tree $S$, a reconciliation is a mapping function $m : V(G') \rightarrow V(S)$ that maps each node $u$ of $G'$ to a node $m(u)$ of $S$ (Note: $V(G')$ shows the list of nodes of $G'$). Each leaf of $G'$ represents a distinct extant gene, which can be specified by a function $s : L(G') \xrightarrow{} L(S)$, which means that each extant gene belongs to an extant species. In a DL reconciliation, each internal node of $G'$ is associated to a node of $S$ that represents an eventâ€”a speciation (S) or a duplication (D). Indeed, orthologs are copies in different species related through speciation and gene families are likely to contain paralogs, which are copies that have evolved by duplication. Here are the reconciliation rules:\\

\begin{itemize}
    \item if $u$ is a leaf of $V(G')$, then $m(u)=s(u)$ (Note: $s(u)$ corresponds to the species type of $u$, we assume that we know the species type of the leaves of gene trees).
    \item if $u$ is internal node of $V(S)$, then it maps to a species $m(u) \in V(S)$. %which is the Lowest-Common-Ancestor (LCA) of descending mapped species.
    \item A mapping $m$ is valid if (rules for mapping $m$): maintain time consistency which means for each $u \in V(G')$, $m(parent(u))$ is either $m(u)$ or is an ancestor of $m(u)$.

\end{itemize}


let $u_l$ and $u_r$ be two children of $u$, then:
\begin{itemize}
    %\subitem if $m(u)=m(u_l)$ or $m(u)=m(u_r)$, then $u$ is a duplication node,
    \item $m(u)$ is a speciation if $m(u_r)$ and $m(u_l)$ are incomparable (two nodes are  incomparable if they are not ancestors or descendants of each other) and $m(u)=LCA(m(u_l),m(u_r))$.
    %\subitem otherwise, $u$ is a speciation node.
    \item $m(u)$ is a duplication if $m(u_l)$ and $m(u_r)$ are either $m(u)$ or are descendants of $m(u)$.
\end{itemize}


To find the losses, there are species that do not exist in the path $(m(u), m(u_l))$ and $(m(u), m(u_r))$ for each internal node $u \in V(G')$.\\

\begin{itemize}
    \item if $m(u)$ is a speciation: number of loss for node $u$ is $l(u)=dist(m(u),m(u_l))+dist(m(u),m(u_r))-2$ where $dist$ returns the distance between two nodes (number of edges between two nodes).
    \item if $m(u)$ is a duplication: number of loss for node $u$ is $l_m(u)=dist(m(u),m(u_l))+dist(m(u),m(u_r))$.
\end{itemize}

The total number of losses is:

\begin{align*}
    l_m = \sum_{u \in V(G')} l_m(u)
\end{align*}

Also, to find the segmental duplication by given a set of duplications nodes $D \subseteq V(G')$ occurring in a given node $v \in V(S)$, to see that the minimum number of segmental duplications associated with $v$ is the minimal number of parts in a partition of $D$ in which each part does not contain comparable nodes (comparable nodes are each other's ancestors or descendants) which is equal to the height of the forest of the duplications in $v$ (this number represents the number of segmental duplication in species $v$) that is shown by $H_m(v)$. The total number of segmental duplications is: 

\begin{align*}
    d = \sum_{v \in V(S)} H_m(v)
\end{align*}
    
A most parsimonious reconciliation (MPR), is a reconciliation of minimum cost. To define cost, first of all, it is usually assumed that speciations do not incur cost. Therefore, the cost includes duplicates and losses. Here, we consider segmental duplications and denote the number of segmental duplications by $d$, also denote the number of losses by $l$. So, based on the cost of a segmental duplication $\delta$ and cost of a loss $\lambda$, the cost of reconciliation is $cost = \delta \times d + \lambda \times l$.\\

The main goal is to find the minimum $cost$ by remapping the nodes of $G'$.



\paragraph{Remapping.}  Given a node $u \in V(G')$, a species node $s \in V(S)$ such that $m(u) \prec s$, and a mapping $m$, the \emph{remapping of $u$ to $s$} is another mapping $m[u \rightarrow s]$ in which
\begin{itemize}
    \item 
    $m[u \rightarrow s](w) = s$ for every ancestor $w$ of $u$ such that $m(w) \prec s$;

    \item 
    $m[u \rightarrow s](w) = m(w)$ for every other node of $G'$.
    
\end{itemize}

\section{Greedy Algorithm}
In this section we represent a greedy algorithm for segmental reconciliation problem.


\begin{algorithm}
\caption{Greedy algorithm for segmental reconciliation}\label{alg:cap}
\begin{algorithmic}
\Require a set of gene trees $G'$, a species tree $S$, a LCA-mapping $m$, cost of segmental duplication $\delta$ and cost of loss $\lambda$
\Ensure MPR for segmental duplications
\State $d,l \gets$ Calculate-Num-of-Dups-Losses($G',S, m$)
\State $CurrentCost \gets d.\delta+l.\lambda$
\For{each internal node $u \in V(G')$}
\State Let $X$ be the set of all possible ancestors of $m(u)$
\For{each node $x \in X$}
\State $temp \gets m(u)$
\State $m(u) \gets x$
\State $d,l \gets$ Calculate-Num-of-Dups-Losses($G',S, m$)
\State $Cost \gets d.\delta+l.\lambda$
\If{$Cost < CurrentCost$}
    \State $CurrentCost \gets Cost$
\Else{} 
    \State $m(u) \gets temp$
\EndIf
\EndFor
\EndFor\\
\Return $Cost$
\end{algorithmic}
\end{algorithm}

\section{Extended Greedy Algorithm}
In this section we represent a bottom-up approach for segmental reconciliation problem. First, we use LCA-mapping as initial mapping. Then, it calculates the cost with all possible remapping species for each node in the gene trees and considers the mapping that
represents the minimum cost. In our algorithm, we start from the species
closest to the root of the species tree to avoid recomputing the number of
segmental duplications when remapping a node to all possible species, since
we involve more nodes of gene trees that need to recalculate segmental duplications by remapping to the most distant species. Therefore, by calculating
the number of segmental duplications for all nodes with the first attempt, we
do not need to recalculate the segmental duplications for these nodes as we
proceed to other species.\\

Define some variable as follows:

\begin{itemize}
    \item $D[u,s_i,s_j] = H_{m[u \rightarrow s_i]}(s_j)$, that is the  maximum height of forest of the duplications in $s_j$ species in tree $G$ if we remapped $u$ to $s_i$, where $u \in V(G')$, and $s_i, s_j \in S$.
    \item $D'[u] =$ maximum height of the duplications in $s$ species in subtree rooted at $u$ while $u$ is mapped to the $s$, where $u  \in V(G')$, and $s \in V(S)$.  [TODO: how do we refer to subtree rooted at $u$ that contains only nodes mapped to $m(u)$?]
    
    \item for each node in $G'$, we have $L[u,A] =$  number of losses in tree if remapped to $A$
\end{itemize}

    \begin{figure}[ht]
    \centerline{
    \includegraphics[width=3.5cm]{path578.png}
    }
    \caption{Species tree}
    \label{fig:S}
    \end{figure}

    \begin{figure}[ht]
    \centerline{
    \includegraphics[width=6.5cm]{path579.png}
    }
    \caption{Gene tree}
    \label{fig:G}
    \end{figure}

For example, in \ref{fig:S} and \ref{fig:G} a species tree and a gene tree are shown that duplication nodes are specified with squares. The mapping shown on the gene tree is initial mapping based on the LCA-mapping. We can have following tables for node $u$ in the gene tree.\\

\begin{itemize}
    \item With initial mapping (map $u$ to the $A$): $D[u,A,A] = 2$, $D[u,A,B] = 2$, $D[u,A,C] = 0$ and $D'[u,A]= 1$.

    \item if we remap $u$ to the $B$: $D[u,B,A] = 0$, $D[u,B,B] = 2$, $D[u,B,C] = 0$ and $D'[u,B]= 0$.

    \item if we remap $u$ to the $C$: $D[u,C,A] = 0$, $D[u,C,B] = 1$, $D[u,C,C] = 3$ and $D'[u,C]= 0$.
    
\end{itemize}

Or we can have following tables for node $u'$ in gene tree:\\
\begin{itemize}
    \item With initial mapping (map $u'$ to the $B$): $D[u',B,A] = 2$, $D[u',B,B] = 2$, $D[u',B,C] = 0$ and $D'[u',B]= 2$.

    \item if we remap $u'$ to the $C$: $D[u',C,A] = 2$, $D[u',C,B] = 1$, $D[u',C,C] = 1$ and $D'[u',C]= 0$.\\

    Note: we can not remap $u'$ to the $A$ because the LCA of $c$ and $b$ species is $B$.

    
\end{itemize}


\begin{algorithm}
\caption{Extended greedy algorithm for segmental reconciliation}\label{alg:cap}
\begin{algorithmic}
\Require a set of gene trees $G'$, a species tree $S$, a LCA-mapping $m$, cost of segmental duplication $\delta$ and cost of loss $\lambda$
\Ensure MPR for segmental duplications


\State Let $d$ be the number of segmental duplication over $G'$
\State Let $l$ be the number of losses over $G'$
\State $CurrentCost \gets d.\delta+l.\lambda$

\For{each internal node $u \in V(G')$}
    \State Let $X$ be the set of all possible ancestors of $m(u)$
    \State Sort $X$ based on the level in $S$
    \State ancestors[]
    \For{$i$ from $u$ to $root$}
        \State ancestors.add($m(i)$)
        \State $u=p(u)$
    \EndFor
    \For{each node $x \in X$ from last to first}
        \State let $modified\_species$ be a set of modified species from $u$ to $m(p(u))=x$
        \State let $modified\_species\_ack$ be a acknowledgement of modified species when they are recalculated (intial with false)
        \State //remap ancestors to $x$;
        \For{$i$ from $u$ to $m(p(u))=x$}
            \State $temps \gets m(u)$
            \State $modified\_species.add(m(i))$
            \State $m(i) \gets x$
            
        \EndFor
    
        \For{each $s_i \in modified\_species$}
            \If{$modified\_species\_ack(s_i)=False$ or $s_i=x$}
                \State $D[u, x, s_i] = recalculate\_max\_height(s_i)$
                \State $modified\_species\_ack(s_i)=True$
            \EndIf
        \EndFor

        \State Let $d$ be the new number of segmental duplication over $G'$
        \State Let $l$ be the new number of losses over $G'$
        \State $Cost \gets d.\delta+l.\lambda$
        \If{$Cost < CurrentCost$}
            \State $CurrentCost \gets Cost$
        \Else{} 
            \State $m(u) \gets temps$
        \EndIf
        
    \EndFor



    
\EndFor
\\

\Return $Cost, m$
\end{algorithmic}
\end{algorithm}


\newpage

\section{A top-down approach}

For one node $u$, the above algorithm
takes time $O(h(S)^2 \cdot h(G))$, multiplied by the time needed for $recalculate\_max\_height$, whose status is still unknown (here, $h(S)$ and $h(G)$ are the heights of $S$ and $G$, respectively).  If the recalculation introduces yet another multiplicative factor, this might be a bit inefficient.

I suggest we focus on how $D[u, s_i, s_j]$ can be computed.  We could try to express $D[u, s_i, s_j]$ in terms of $D[p(u), s_i, s_j]$, where $p(u)$ is the parent of $u$.
It seems to me that $u$ and $p(u)$ must accomplish essentially the same work in the above procedure, so it might make sense to develop a top-bottom recurrence.  

To compute $D[u, s_i, s_j]$, there are two cases:
\begin{itemize}
    \item 
    $s_i \prec m(p(u))$.  In this case, when we remap $u$ to $s_i$, no other node needs to be remapped.  
    Therefore, only $D[u, s_i, s_i]$ 
    and $D[u, s_i, m(u)]$ can change in $m[u \rightarrow s_i]$. 
    
    I believe that $D[u, s_i, s_i] = \max (H_m(s_i), 1)$, since remapping $u$ to $s_i$ creates a new duplication subtree in $s_i$ of height $1$.

    As for $D[u, s_i, m(u)]$, let $u_l, u_r$ be the children of $u$.  We need to check the height of the dup subtrees in $m(u)$ rooted at $u_l$ and $u_r$ (using $D'[u_l]$ and $D'[u_r]$), and compare that against 
    $H_m(m(u))$.  One problem is that we do not know whether $u$ was responsible for $H_m(s_i)$, so we might need some other data structure to handle that.

    \item 
    $s_i \succeq m(p(u))$.  In this case, $p(u)$ needs to be remapped to $s_i$, as well as other ancestors, possibly.  

    If $s_j \neq s_i$, then I believe that $D[u, s_i, s_j] = D[p(u), s_i, s_j]$.

    Suppose that $s_j = s_i$.  
    We need to find $w$, the highest ancestor of $u$ mapped to $s_i$ in $m[u \rightarrow s_i]$.  
    We need to check the height of duplication subtree in $s_i$, rooted at $w$.  If will be either $D[p(u), s_i, s_i]$ or $D[p(u), s_i, s_i] + 1$, depending on whether $u$ increases the height of this subtree or not.  Is there an efficient way to check that and compare it against $H_m(s_i)$?
    
\end{itemize}

\subsection*{Notes on complexity}

The above description suggests that each $D[u, s_i, s_j]$ could be computed in time $O(h(G))$ with appropriate data structures, where the $h(G)$ is to find the aforementioned $w$. Maybe it can be optimized to take $O(1)$ per entry instead.
In any case, the number of $D$ entries is $O(|V(G)| h(S)^2)$, so filling them takes time $O(|V(G)| h(S)^2 h(G))$.

This is ok if we only do it once, but updates need to be faster than that.
We should evaluate the complexity of the naive algorithm, which just recomputes a reconciliation for every move, and make sure we achieve a significant gain against that.
I believe the naive algorithm can be implemented to take time $O(|V(G)|^2h(S))$.

\subsection*{Data structure}

We can consider kind of hash table as our data structure where the keys of hash table are species. Also, the entries of hash table are [$H_m(s_i)$, Node ID] (that can be sorted in each row or not?). Moreover, $D[u,s_i,s_j]$ values can be pointers to the cells of hash table.\\
For example, $s_0, s_1, ... , s_n$ are all species in species tree and each cell [$H_m(s_i)$, Node ID] shows the number of segmental duplication ($H_m(s_i)$) in species $s_i$ which is observed in a node in gene tree with Node ID. Also, $D[N4,s2,s2]$ will be a pointer to the [$H_m(s_2)$,N4]. \\ 



\begin{hashtable}
   $s_0$ & [$H_m(s_0)$,N1] $\rightarrow$ [$H_m(s_0)$,N2]\\
   $s_1$ & [$H_m(s_1)$,N3] \\
   $s_2$ & [$H_m(s_2)$,N4] $\rightarrow$ [$H_m(s_2)$,N5] $\rightarrow$ [$H_m(s_2)$,N6]\\
   $s_i$ &  $NULL$ \\
   $s_n$ & [$H_m(s_n)$,N7] 
\end{hashtable}\\

So, we have one hash table for each gene tree based on the new data structure. For each node, we try all possible remapping just before a remapping action we get a backup of those rows in hash table that will change by remapping action and if the cost increases, we return the hash table to the previous state by using backup. We can redefine algorithm using new data structure as Algorithm \ref{alg:cap2}. There are two function called $remove()$ and $add()$ that are able to remove/add a cell from/to hash table. The $add()$ function will add the new cell based on the $H_m()$ value in a way that the row of species is always sorted. Also, the $remove()$ function only looks for the node ID in the species row and then only deletes the cell.\\
\textbf{NOTE:} In the hash table we consider different cells (values) for different nodes of a chain of duplication in one species. For instance, the hash table for shown duplication chain in Figure \ref{fig:chain} would be:\\

\begin{hashtable}
   $s$ & [$3$,N4] $\rightarrow$ [$2$,N3] $\rightarrow$ [$1$,N2]\\
\end{hashtable}\\

So, if we call $remove([3,N4])$ function, we don't need to update other cells.

    \begin{figure}[ht]
    \centerline{
    \includegraphics[width=2.5cm]{bitmap.png}
    }
    \caption{Duplication chain in $s$ species}
    \label{fig:chain}
    \end{figure}




\begin{algorithm}
\caption{modified version}\label{alg:cap2}
\begin{algorithmic}
\Require a set of gene trees $G_1, G_2, ... , G_n$, a species tree $S$, a LCA-mapping $m$, cost of segmental duplication $\delta$ and cost of loss $\lambda$
\Ensure MPR for segmental duplications


\State Let $d$ be the number of segmental duplication over $G'$
\State Let $l$ be the number of losses over $G'$
\State $CurrentCost \gets d.\delta+l.\lambda$
\State Let $H_1, H_2, ... , H_n$ be hash table for $G_1, G_2, ... , G_n$ respectively\\
\For{each gene tree $G_i \in {G_1, G_2, ... , G_n}$}
\For{each internal node $u \in V(G_i)$}
    \State Let $remapping\_species$ be list of all possible remapping species for $u$\\

    \For{each node $s \in remapping\_species$}
        \State Let $backup$ be a backup of $H_i$
        \If{$s_i \prec m(p(u))$}
            \State $remove$ [$H_m(m(u))$,u] from $m(u)$ row of $H_i$ if $u$ is a duplication
            \State $add$ [$H_m(s)$,u] to $s$ row of $H_i$ if $u$ is a duplication
        \Else{ $ s_i \succeq m(p(u))$} 
            \State Let $w$ be the highest ancestor of $u$ that should mapped to $s$
            \State call $remove()$ and $add()$ for $n$ which is $u \leq n \leq w$ 
        \EndIf
\\
        \State Let $d$ be the new number of segmental duplication over $G'$
        \State Let $l$ be the new number of losses over $G'$
        \State $Cost \gets d.\delta+l.\lambda$
        \If{$Cost < CurrentCost$}
            \State $CurrentCost \gets Cost$
        \Else{} 
            \State $H_i \gets backup$
        \EndIf
    \EndFor
\EndFor
\EndFor
\\

\Return $Cost, m$
\end{algorithmic}
\end{algorithm}
\begin{table}[!h]
\begin{center}
\begin{tabular}{ |p{3cm}||p{2.5cm}|p{3.4cm}|p{3.1cm}|  }
 \hline

 \hline
 Algorithm& small dataset & full genetrees(2700) & large dataset(10000) \\
 \hline
 LCA & 0 sec & 2 sec & 4 sec \\
 old implementation   &  0 sec  & ? (running) & more than 1 day\\
 ultra greedy &   0 sec  & 2.7 min (2.51 min) & 12 min\\
 true greedy & 0 sec & 26.51 min (15.85 min) & 6.81 hours\\

 \hline

\end{tabular}
\caption{\label{exe-time}Execution time of algorithms.}
\end{center}
\end{table}

\begin{table}[!h]
\begin{center}
\begin{tabular}{ |p{3cm}||p{2.5cm}|p{3.4cm}|p{3.1cm}|  }
 \hline

 \hline
 Algorithm& small dataset & full genetrees(2700) & large dataset(10000) \\
 \hline
 LCA & 255.5 & 3427 & 11023 \\
 old implementation   &  249  & ? (running) & ?\\
 ultra greedy &   252.5  & 3418.5 & 11005\\
 true greedy & 252.5 & 3413 & ?\\

 \hline

\end{tabular}
\caption{\label{cost}Obtained cost of algorithms ($d=5,l=0.5$).}
\end{center}
\end{table}

Table \ref{cost2} for simulated gene trees with:\\
"./simphy -sb f:0.000001 -ld f:0.0000005 -lb f:0.0000005 -lt f:0.0000005 -rs 1 -rl U:10,100 -rg 1 -o SimPhy\_test -sp f:10000 -su f:0.00001 -sg f:1 -sl U:20,50 -st f:1000000 -om 1 -v 3 -od 1 -op 1 -oc 1 -on 1 -cs 22".

\begin{table}[!h]
\begin{center}
\begin{tabular}{ |p{3cm}||p{3cm}|p{3cm}|  }
 \hline

 \hline
 Algorithm& cost & running time \\
 \hline
 LCA & 2097 & 0 sec \\
 old implementation   &  ?  & ?  \\
 ultra greedy &   2046  & 1 sec\\
  true greedy & 2002.5 & 7 sec \\

 \hline

\end{tabular}
\caption{\label{cost2}}
\end{center}
\end{table}


\newpage

\section*{Reconciliation comparison metric}

Let $G$ be a gene tree (or a gene forest) and let $S$ be a species tree.
Suppose we have two reconciliations $\mu : V(G) \rightarrow V(S)$ and $\tau : V(G) \rightarrow V(S)$. 
Here, $\mu$ can be thought of as an inferred mapping, and $\tau$ as the ``true'' mapping.
We define the metric $diff(\mu, \tau)$ to quantify the differences between $\mu$ and $\tau$, based on the distances between mapped species of each gene as follows:
\[
diff(\mu, \tau) = \sum_{v \in V(G)} dist_S( \mu(v), \tau(v) )
\]
where $dist_S(x, y)$ is the distance between nodes $x$ and $y$ in $S$.

\section*{Results related to the comparison of mappings and the costs of each mapping}

In all simulations $\delta=5$ and $\lambda=0.5$.

\subsection{First Simulation}
Simphy Parameters: $./simphy -sb f:0.000001 -ld f:0.0000005 -lb f:0.0000005 -lt f:0.0000005 -rs 1 -rl U:10,100 -rg 1 -o SimPhy\_test -sp f:10000 -su f:0.00001 -sg f:1 -sl U:20,50 -st f:1000000 -om 1 -v 3 -od 1 -op 1 -oc 1 -on 1 -ol 1 -cs 22$.\\
duplication rate (-lb): f:0.0000005\\
loss rate (-ld): f:0.0000005\\
transfer rate (-lt): f:0.0000005\\

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|l|}
\hline
\textbf{Algorithm} & \textbf{Simphy} & \textbf{LCA} & \textbf{Greedy} & \textbf{UltraGreedy}      \\ \hline
\textbf{Simphy}    & 0               & 2723         & 2743            & \multicolumn{1}{c|}{2746} \\ \hline
\end{tabular}
\caption{\label{dist1}Distance between mappings.}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Algorithm}   & \textbf{Cost} & \textbf{Dup Height} & \textbf{Nb Losses} \\ \hline
\textbf{Simphy}      & 4299.5        & 56                  & 8039               \\ \hline
\textbf{LCA}         & 2012          & 92                  & 3104               \\ \hline
\textbf{Greedy}      & 1915          & 68                  & 3150               \\ \hline
\textbf{UltraGreedy} & 1951.5        & 75                  & 3153               \\ \hline
\end{tabular}
\caption{\label{cost1}Cost of each mapping.}
\end{center}
\end{table}

\subsection{Second Simulation}
Simphy Parameters: $./simphy -sb f:0.000001 -gb u:-30,-30 -gt f:gb -ld ln:gb,7 -lb f:ld -lt ln:gt,0.4 -rs 1 -rl U:10,100 -rg 1 -o dist_test -sp f:10000 -su f:0.00001 -sg f:1 -sl U:20,50 -st f:1000000 -om 1 -v 3 -od 1 -op 1 -oc 1 -on 1 -ol 1 -cs 22$.\\
duplication rate (-lb): f:(ln:(u:-30,-30),7) \\
loss rate (-ld): ln:(u:-30,-30),7 \\
transfer rate (-lt): ln:(f:(u:-30,-30),0.4)\\

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|l|}
\hline
\textbf{Algorithm} & \textbf{Simphy} & \textbf{LCA} & \textbf{Greedy} & \textbf{UltraGreedy}      \\ \hline
\textbf{Simphy}    & 0               & 1339         & 1343            & \multicolumn{1}{c|}{1342} \\ \hline
\end{tabular}
\caption{\label{dist1}Distance between mappings.}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Algorithm}   & \textbf{Cost} & \textbf{Dup Height} & \textbf{Nb Losses} \\ \hline
\textbf{Simphy}      & 4468        & 25                  & 8686               \\ \hline
\textbf{LCA}         & 131          & 19                  & 72               \\ \hline
\textbf{Greedy}      & 114          & 14                  & 88               \\ \hline
\textbf{UltraGreedy} & 118        & 15                  & 86               \\ \hline
\end{tabular}
\caption{\label{cost1}Cost of each mapping.}
\end{center}
\end{table}

\subsection{Third Simulation}
Simphy Parameters: $./simphy -sb f:0.000001 -gb u:-30,-28 -gt f:gb -ld ln:gb,7 -lb f:ld -lt f:0.0 -rs 1 -rl U:10,100 -rg 1 -o dist_test_2 -sp f:10000 -su f:0.00001 -sg f:1 -sl U:20,50 -st f:1000000 -om 1 -v 3 -od 1 -op 1 -oc 1 -on 1 -ol 1 -cs 22  $.\\
duplication rate (-lb): f:(ln:(u:-30,-28),7) \\
loss rate (-ld): ln:(u:-30,-28),7 \\
transfer rate (-lt): f:0.0\\

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|l|}
\hline
\textbf{Algorithm} & \textbf{Simphy} & \textbf{LCA} & \textbf{Greedy} & \textbf{UltraGreedy}      \\ \hline
\textbf{Simphy}    & 0               & 1354         & 1354            & \multicolumn{1}{c|}{1354} \\ \hline
\end{tabular}
\caption{\label{dist1}Distance between mappings.}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Algorithm}   & \textbf{Cost} & \textbf{Dup Height} & \textbf{Nb Losses} \\ \hline
\textbf{Simphy}      & 4448.5        & 13                  & 8767               \\ \hline
\textbf{LCA}         & 58          & 4                  & 76               \\ \hline
    \textbf{Greedy}      & 58          & 4                  & 76               \\ \hline
\textbf{UltraGreedy} & 58        & 4                  & 76               \\ \hline
\end{tabular}
\caption{\label{cost1}Cost of each mapping.}
\end{center}
\end{table}

\subsection{Forth Simulation}
Simphy Parameters: $./simphy -sb f:0.000001 -gb u:-30,0 -gt f:gb -ld ln:gb,2 -lb f:ld -lt f:0.0 -rs 1 -rl U:10,100 -rg 1 -o dist_test_4 -sp f:10000 -su f:0.00001 -sg f:1 -sl U:20,50 -st f:1000000 -om 1 -v 3 -od 1 -op 1 -oc 1 -on 1 -ol 1 -cs 22  $.\\
duplication rate (-lb): f:(ln:(u:-30,0),2) \\
loss rate (-ld): ln:(u:-30,0),2 \\
transfer rate (-lt): f:0.0\\

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|l|}
\hline
\textbf{Algorithm} & \textbf{Simphy} & \textbf{LCA} & \textbf{Greedy} & \textbf{UltraGreedy}      \\ \hline
\textbf{Simphy}    & 0               & 1349         & 1384            & \multicolumn{1}{c|}{1378} \\ \hline
\end{tabular}
\caption{\label{dist1}Distance between mappings.}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Algorithm}   & \textbf{Cost} & \textbf{Dup Height} & \textbf{Nb Losses} \\ \hline
\textbf{Simphy}      & 4647.5        & 113                  & 8165               \\ \hline
\textbf{LCA}         & 785.5          & 122                  & 351               \\ \hline
    \textbf{Greedy}      & 648.5          & 83                  & 467               \\ \hline
\textbf{UltraGreedy} & 738        & 104                  & 436             \\ \hline
\end{tabular}
\caption{\label{cost1}Cost of each mapping.}
\end{center}
\end{table}




\section{Attempt at something faster}

For $u \in V(G)$ and $s, t \in V(S)$, 
we denote $\Delta(u, s, t) = H_{m[u \rightarrow s]}(t) - H_m(t)$, which is the change in duplication height in species $t$ after remapping $u$ to $s$. 
Then denote
\[
\Delta(u, s) = \sum_{t \in V(S)} \Delta(u, s, t)
\]
which is the \emph{total} change in duplication heights after remapping $u$ to $s$.  Our goal is to fill every $\Delta(u, s)$ entry as efficiently as possible.  The first important step is the following.

\begin{lemma}\label{lem:deltasum}
    Let $u \in V(G)$ and let $s \in V(S)$ be an ancestor of $m(u)$.
    If $u$ is a root, or if $u$ has a parent $p_u$ and $s \prec m(p_u)$, then
    \[
    \Delta(u, s) = \Delta(u, s, s) + \Delta(u, s, m(u)).
    \]
    Otherwise, if $u$ has a parent $p_u$ and $s \succeq m(p_u)$, then
    \begin{align*}
    \Delta(u, s) = \Delta(p_u, s) &~- \Delta(p_u, s, s) - \Delta(p_u, s, m(u)) \\
    &~+ \Delta(u, s, s) + \Delta(u, s, m(u))
    \end{align*}
\end{lemma}

\begin{proof}
    (sketch) 
    If $u$ is a root, then only the duplication height in $s$ or $m(u)$ can change by remapping $u$ to $s$ \ml{(why?)}.  
    If $u$ is not a root but $s \prec m(p_u)$, only $m(u)$ changes, and thus only the duplication height in $s$ or $m(u)$ can be affected.

    So assume that $s \succeq m(p_u)$.
    Let $t \in V(S) \setminus \{s, m(u)\}$. 
    We claim that $\Delta(u, s, t) = \Delta(p_u, s, t)$.  The idea is that when remapping $p_u$ to $s$ but not $u$, the height in $t$ gets affected in some way.  If we then remap $u$ to $s$ in this new mapping, the height in $t$ won't be affected further.
    It follows that 
    \begin{align*}
        \Delta(u, s) &= \sum_{t \in V(S)} \Delta(u, s, t) \\
        &= \sum_{t \in V(S) \setminus \{s, m(u)\}} \Delta(u, s, t) + \Delta(u, s, s) + \Delta(u, s, m(u)) \\
        &= \sum_{t \in V(S) \setminus \{s, m(u)\}} \Delta(p_u, s, t) + \Delta(u, s, s) + \Delta(u, s, m(u)) \\
        &= \Delta(p_u, s) - \Delta(p_u, s, s) - \Delta(p_u, s, m(u)) + \Delta(u, s, s) + \Delta(u, s, m(u))
    \end{align*}
\end{proof}


We deduce from the above that using a top-down approach, one can obtain $\Delta(u, s)$ by reusing $\Delta(p_u, s)$ and computing only four additional  values.

We need auxiliary data structures to achieve this efficiently.

\begin{itemize}
    \item 
    For $s \in V(S)$ and integer $i$, denote by $B[s, i]$ contains the set of nodes of $G$ that are the roots of an $s$-duplication subtree of height $i$.  Note that $H_m(s)$ is the largest integer such that $B[s, H_m(s)]$ is non-empty.


    \item 
    For $u \in V(G)$, let $h_m(u)$ be the height of the duplication subtree in $m(u)$ rooted at $u$.

    \item 
    For $u \in V(G)$ and $s \in V(S)$ an ancestor of $m(u)$ (possibly equal), we define
$c_m(u, s)$ as the number of ancestors of $u$ mapped to $s$ in $m[u \rightarrow s]$ under the assumption that $u$ is a duplication node in this new mapping.  In other words, if we remap $u$ to $s$ and assume that $u$ is a duplication, $c(u, s)$ is the number of vertices in the chain of $s$ that starts at $u$, going upwards.  Note that if $u$ is a speciation, it is assumed to become a duplication even when considering $c_m(u, m(u))$.

    If $u$ is a root, then $c(u, s) = 1$.
    Otherwise, there are two cases. 
    If $s \prec m(p_u)$, then $c(u, s) = 1$ since the parent of $u$ will not be remapped.  
    If $s \succeq m(p_u)$, then $c(u, s) = c(p_u, s) + 1$.
\end{itemize}

We assume that all the entries in $c_m, h_m,$ and $B$ can be computed in total time $O(|V(G)| h(S))$.

We first show how two of the four required values can be obtained easily (see Figure~\ref{fig:deltauss} for an illustration).

    
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{deltauss.png}
    \caption{Illustration of the cases covered by Lemma~\ref{lem:deltauss}.  Top shows $\Delta(u, s, s)$: the new height in $s$ in $m[u \rightarrow s]$ is either the chain in $s$ that ends at $u$, or the height of a subtree that was already there.
    Bottom is $\Delta(p_u, s, m(u))$: if $m(p_u) \succ m(u)$, then in $m[p_u \rightarrow s]$ only ancestors of $p_u$ are affected, which does not change the height in $m(u)$.  Otherwise, $m(p_u) = m(u)$, as stated in Lemma~\ref{lem:deltauss}.}
    \label{fig:deltauss}
\end{figure}



\begin{lemma}\label{lem:deltauss}
    Let $u \in V(G)$ and let $s \in V(S)$ be a strict ancestor of $m(u)$.  Then the following holds:
    \begin{itemize}
    \item 
    $\Delta(u, s, s) = \max(c_m(u, s), H_m(s)) - H_m(s)$.
    
    \ml{[ML: this was changed, previously the subtraction was in the reverse order]}
    
    

    \item 
    Suppose that $u$ has a parent $p_u$.  Then 
    \begin{align*}
        \Delta(p_u, s, m(u)) = \begin{cases}
            0 &\mbox{ if $m(u) \prec m(p_u)$} \\
            \Delta(p_u, s, m(p_u)) &\mbox{ otherwise.} \\
        \end{cases}   
    \end{align*}
\end{itemize}
\end{lemma}

\begin{proof}
    (sketch)
    For $\Delta(u, s, s)$, The intuition is that the highest duplication subtree at $s$ is either a subtree that was already there, or is obtained from the chain of $s$ that ends at $u$.

    For $\Delta(p_u, s, m(u))$, if $m(u) \prec m(p_u)$, then notice that no ancestor of $p_u$ is mapped to $m(u)$.  Therefore, remapping $p_u$ to $s$ cannot affect the height in $m(u)$ \ml{(what if $s = m(u)$?)}.
    If instead $m(u) \succeq m(p_u)$, then by time-consistency, only $m(u) = m(p_u)$ is possible, hence $\Delta(p_u, s, m(u)) = \Delta(p_u, s, m(p_u))$.
\end{proof}


We next show how $\Delta(u, s, m(u))$ can be obtained (see Figure~\ref{fig:deltamusmu}).

\begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{deltamusmu.png}
    \caption{Illustration of the case $m(u) \neq m(p_u)$ in Lemma~\ref{lem:deltamusmu}, when $\delta(u, s, m(u))$ is set to $-1$.  
    If $u$ is the only element of $B[m(u), H_m(m(u))]$, then $u$ the root root of the unique maximum height subtree in $m(u)$.  In $m[u \rightarrow s]$, this height is reduced by $1$ and one of the children of $u$ becomes the root of the next highest subtree in $m(u)$, if any.}
    \label{fig:deltamusmu}
\end{figure}


\begin{lemma}\label{lem:deltamusmu}
    Let $u \in V(G)$ be a non-root node with parent $p_u$ and let $s \in V(S)$ be an ancestor of $m(u)$.  Then: {\ml{what if $u$ is a root?}}
    \begin{itemize}
        \item 
        if $m(u) \neq m(p_u)$, then
        \begin{align*}
            \Delta(u, s, m(u)) = \begin{cases}
                -1 &\mbox{if  $B[m(u), H_m(m(u))] = \{u\}$} \\
                0 &\mbox{ otherwise} 
            \end{cases}
        \end{align*}

        \ml{[ML: I put back $-1$ in the first case above]}

        \item 
        if $m(u) = m(p_u)$, then let $h' = H_m(m(u)) + \Delta(p_u, s, m(u))$, which is the height in $m(u)$ if we remap $p_u$ to $s$.  \ml{[ML: I put back a ``$+$'' in the definition of $h'$ (we changed it to a minus in our last meeting, but it should be a plus now)]}
        Then
        \begin{align*}
            \Delta(u, s, m(u)) = \Delta(p_u, s, m(u)) + \begin{cases}
                0 &\mbox{ if $h' \neq h_m(u)$} \\
                -1 &\mbox{ if $h' = h_m(u)$ but $B[m(u), h'] = \{u\}$} \\
                0 &\mbox{ if $h' = h_m(u)$ but $B[m(u), h'] \neq \{u\}$} 
            \end{cases}
        \end{align*}

        \ml{[ML: I put back $-1$ in the second case above]}
    \end{itemize}
\end{lemma}

\begin{proof}
    (sketch) Suppose that $m(u) \neq m(p_u)$.  Then by remapping $u$ and possibly some of its other ancestors, $u$ is the only node that could affect the height in $m(u)$.  If $u$ is not the root of a duplication subtree in $m(u)$ of height $H_m(m(u))$, then such a subtree remains present under $m[u \rightarrow s]$, and thus $\Delta(u, s, m(u))$ must be $0$.  This is what our above equality puts,  since $B[m(u), H_m(m(u))]$ does not even contain $u$. 
    So suppose that $u$ is the root of a subtree in $m(u)$ of height $H_m(m(u))$.  If some subtree of the same height in $m(u)$ rooted at some $v \neq u$ is present under $m$, it remains in $m[u \rightarrow s]$ and $\Delta(u, s, m(u))$ must be $0$.  This is what our above equality puts since $v$ is in $B[m(u), H_m(m(u))]$.  
    Finally, if $u$ is the only such subtree, then by remapping it there can be no more subtree of height $H_m(m(u))$ under $m$.  The largest possible height in $m(u)$ is then $H_m(m(u)) - 1$, which is achieved by one of the children of $u$.  In this case, the duplication height in $m(u)$ is reduced by $1$.  Since in this last case $B[m(u), H_m(m(u))] = \{u\}$, this justifies putting $-1$ in this case.

    Next suppose that $m(u) = m(p_u)$.  Let $h'$ be the height in $m(u)$ under $m[p_u \rightarrow s]$.  If $h' \neq h_m(u)$, then some subtree of height $h'$ in $m(u)$ is present under $m[p_u \rightarrow s]$ and is not rooted at $u$, and this subtree is also present under $m[u \rightarrow s]$.  \ml{(argue that $h' > h_m(u)$)} Hence putting $\Delta(u, s, m(u)) = \Delta(p_u, s, m(u))$ is correct.
    
    So assume that $h' = h_m(u)$. 
    Let $h_u$ be the height of a subtree in $m(u)$ under $m[u \rightarrow s]$.  Notice that $h_u \leq h'$ since there are less nodes mapped to $m(u)$ under $m[u \rightarrow s]$ than $m[p_u \rightarrow s]$ \ml{(here we have to argue that $p_u$ gets remapped)}
    Let $v$ be a subtree of height $h'$ in $m(u)$ under $m[p_u \rightarrow s]$.  Then $v$ cannot be an ancestor of $p_u$.  If $v \neq u$, $v$ is present under all of $m, m[u \rightarrow s]$ and $m[p_u \rightarrow s]$ and thus $h_u \geq h'$.  Combined with $h_u \leq h'$ implies $h_u = h'$, and so $\Delta(u, s, m(u)) = \Delta(p_u, s, m(u))$.  If such a $v$ exists, this is what the above equality puts since $v$ is in $B[m(u), h']$.  
    If no such $v$ exists, then $u$ must be the only subtree in $m(u)$ of height $h'$ under \ml{(todo, finish this later)}.
\end{proof}


We have gathered all the necessary steps to compute $\Delta(u, s)$ for every $u \in V(G)$ and $s \succ m(u)$.  They can be summarized as follows.

\begin{enumerate}
    \item 
    Compute $h_m(u)$ for every $u \in V(G)$.  This can be achieved in time $O(|V(G)|)$ through a post-order traversal of $G$ and the following recurrence.  If $u$ is a speciation, then $h_m(u) = 0$.  If $u$ is a duplication, then $h_m(u) = 1 + \max_{v \in C(u)} h_m(v)$, where $C(u)$ is the set of children of $u$ mapped to $m(u)$.  The maximum is defined as $0$ if $C(u)$ is empty.
    
    
    \item 
    Compute the $B$ data structure.  Assuming $O(1)$ time for searching and inserting into hash tables, $B$ can be filled in time \ml{(???)} as follows.  
    For each $u \in V(G)$, we add $u$ to $B[s, h_m(u)]$.

    \item 
    Compute $c_m(u, s)$ for every $u \in V(G)$ and $s \succ m(u)$.  This can be achieved in time $O(|V(G)| h(S))$ through a pre-order traversal of $G$ and the recurrence given before, as each entry can be computed in time $O(1)$.

    \item 
    Compute $\Delta(u, s)$ for every $u \in V(G)$ and $s \succ m(u)$.  This can be achieved in time $O(|V(G)| h(S))$ through a pre-order traversal of $G$ and the above lemmata.  

    Specifically, for each $u$ and $s$, we compute $\Delta(u, s, s)$ using Lemma~\ref{lem:deltauss} and $\Delta(u, s, m(u))$ using Lemma~\ref{lem:deltamusmu} and store them for later usage.
    This means that $\Delta(p_u, s, s)$ is stored when computing $\Delta(u, s)$. 
    Moreover $\Delta(p_u, s, m(u))$ is also obtainable in constant time, since it is either $0$ or $\Delta(p_u, s, m(p_u))$, which is also stored.  Therefore, each term required by Lemma~\ref{lem:deltasum} can be obtained in constant time, and so $\Delta(u, s)$ can be computed in constant time.
 
\end{enumerate}

\subsection{Total change in number of losses}

%\ml{[ML: because of the sum on $c_s(u, s)$, a single entry $\Delta L(u, s)$ will take time $O(h(S))$ to compute, and thus the set of all $\Delta L(u, s)$ entries will take time $O(|V(G)| h(S)^2)$.  This is worse than computing the dup heights.
%It should be possible to achieve constant time per entry if $\Delta L(u, s)$ uses $\Delta(p_u, s)$.
%]}

%\ml{[ML: also, I suggest using $\Lambda(u, s)$ for the loss table. 
% $\Delta$ is the greek ``D'' and stands for duplication, $\Lambda$ is the greek ``L'' and stands for Loss.]}

For $u \in V(G)$ and $s \in V(S)$,  we denote $\Lambda(u, s)$ as the total change in the number of losses after remapping $u$ to $s$. Also, we denote $NL(u, s)$ as the total number of losses after remapping $u$ to $s$.\\
\[
\Lambda(u, s) = NL(u, s) - NL(u, m(u))
\]
%we denote $\Lambda(u, s, v)$, which is the number of losses in a subtree rooted at $v$ after remapping $u$ to $s$. 



%\ml{[ML: this is not clear to me.  The way I see $NL(u, s, v)$ is that it is the total number of losses in all the branches descending from $v$.  By summing for every $v$, a loss will be counted once for every ancestor of the branch containing the loss.]}

%Furthermore, we can define a hypothetical database called $DL(u,m(u))$ that stores the number of losses when $u$ maps to $m(u)$ \ml{[ML: is $NL(u, m(u))$ that same as $DL(u, m(u))$? \rk{Yes.}]}. The reason why we call it hypothetical is that we will see later that we don't need it.



For a mapping $m'$, we define:

        \begin{align*}
            i_{m'}(u) = \begin{cases}
                0 &\mbox{if  $u$ is duplication under $m'$} \\
                2 &\mbox{if  $u$ is speciation under $m'$}
            \end{cases}
        \end{align*}


Also, we define $dist(a,b)$ as the number of arcs on the path from $a$ to $b$ in species tree.
Finally, we define $\lambda(u,s)$ as the total change in the number of losses between $u$ and its children that is:

    \begin{align*}
    \lambda(u, s) = dist(s , m(u_l)) &+  dist(s , m(u_r))
    -  dist(m(u), m(u_l))\\
    &-  dist(m(u) , m(u_r)) + i_{m}(u).
    \end{align*}
     

\begin{lemma}\label{lem:firstcaseloss}
    Let $u \in V(G)$ and let $s \in V(S)$ be an ancestor of $m(u)$.
    If $u$ is a root, then
    \begin{align*}
    \Lambda(u, s) = \lambda(u,s)
    \end{align*}

%\ml{[ML: what is $c_s(u, s)$?  I defined $c_m$ above, where $m$ is a mapping.  Here $s$ is a species, so it's a different concept.  Also, $c_m$ above is defined as an integer (the length of the chain), here it is used as a set.]}
     Otherwise, if $u$ has a parent $p_u$ and $s \preceq m(p_u)$, then

    \begin{align*}
    \Lambda(u, s) = \lambda(u, s) &+  dist(m(p_u) , s) - i_{m[u \rightarrow s]}(p_u) \\
    &-  dist(m(p_u) , m(u)) + i_{m}(p_u).
    \end{align*}
     
    
    Otherwise, if $u$ has a parent $p_u$ and $s \succ m(p_u)$, then
    \begin{align*}
    \Lambda(u, s) = \Lambda(p_u, s) - dist(s, m(u)) + \lambda(u, s)
    \end{align*}
        %{\sum_{v \in c_s(u, s)} \Bigl(dist(s, m(v_l)) + dist(s, m(v_r)) - dist(m(v), m(v_l)) - dist(m(v), m(v_r)) -i_{m(v)} \Bigl) + dist(s , m(u_l)) +  dist(s , m(u_r)) -  dist(m(u), m(u_l)) - dist(m(u), m(u_r)) - i_{m(u)}.}
\end{lemma}

\begin{proof}
    (sketch) 
    If $u$ is a root, only the number of losses in root at $u$ can change by remapping $u$ to $s$. So, the only number of losses that can change are between $u$ and its children.
    %\ml{[ML: I believe this is true if $u$ is the root of a gene tree, but if $u$ has a parent, we might save some losses on the branch between $u$ and its parent.  So unlike dup heights, I think you need three separate cases, one for when $u$ is a root, when $u$ has a parent and $s \prec m(p_u)$, and when $s \succeq m(p_u)$.  Moreover, the case $s = m(p_u)$ looks special, so it might need a fourth case, I'm not sure. \rk{I considered $s = m(p_u)$ with $s \prec m(p_u)$, I think they behave similarly, but I need to check them. }]}. 
    Also, we know that by remapping $u$ to $s$, $u$ becomes duplication, then $i_{m[u \rightarrow s]}(u)$ becomes 0. Then,

    %\begin{align*}
    %NL(u, s) = DL(u, m(u)) &+ dist(s , m(u_l)) +  dist(s , m(u_r))\\ 
    %&- dist(m(u) , m(u_l)) - dist(m(u) , m(u_r)) + i_{m}(u)
    %\end{align*}

%We know $DL(u, m(u))=NL(u, m(u))$. So,

    \begin{align*}
    \Lambda(u, s) &= NL(u, s) - NL(u, m(u)) \\
    &=  dist(s , m(u_l)) +  dist(s , m(u_r)) -  dist(m(u), m(u_l)) \\
    &- dist(m(u), m(u_r)) + i_{m}(u)\\
    &= \lambda(u, s).
    \end{align*}

    If $u$ is not a root but $s \preceq m(p_u)$, then we need to consider changes between $u$ and its children and the distance between $m(p_u)$ and $m(u)$ before and after remapping $u$ to $s$. Also, we need to consider if $p_u$ was a dup or spec or becomes dup or spec after remapping $u$ to $s$, so:

    \begin{align*}
    \Lambda(u, s) = \lambda(u, s) + dist(m(p_u) , s) &- i_{m[u \rightarrow s]}(p_u)  -  dist(m(p_u) , m(u)) + i_{m}(p_u)\\
    \end{align*}


    If we assume that $s \succ m(p_u)$. In this case, the number of losses of all ancestors of $u$ that map to $s$ will change. Therefore, in this case, we consider the total change in the number of losses when $p_u$ it is mapped to $s$, in addition to the change in the number of losses in the arcs between $u$ and its children. Just remember that when we calculate the total change in loss  for $\Lambda(p_u, s)$ , we considered $m(u)$ as the mapping for $u$ while now $u$ is mapped to $s$ , so, we need to decrease 
    $dist(s,m(u)) + i_{m}(p_u)$ and add $dist(s,s) - i_{m[u \rightarrow s]}(p_u)$, where $dist(s,s)$ is 0. Also, $p_u$ is duplication in both cases, so $i_{m}(p_u)$ and $i_{m[u \rightarrow s]}(p_u)$ are 0.
    %Also, we know that $p_u$ is always a duplication in this case, so $i_{m(p_u)}=0$ 
    %\ml{[ML: not sure about that.  Under $m$, $p_u$ could have been a spec or a dup, I think both are possible.  I think the intent of $i_{m(p_u)}$ is ``is $p_u$ a dup or spec if we remap it to $s$'', so maybe it would be clearer to let $i$ depend on a mapping instead of on a species.  It should look more like $i_m(p_u)$ or $i_{m[p_u \rightarrow s]}(p_u)$. Other note, if $s = m(p_u)$, it's possible that $p_u$ is a speciation under both $m$ and $m[p_u \rightarrow s]$ because these are the same. \rk{I agree it makes more sense now, just about $i_{m[p_u \rightarrow s]}(p_u)$ when we want remap $u$ to $s$ and $s \succeq m(p_u)$. Is not $p_u$ always a duplication? So, this means $i_{m[p_u \rightarrow s]}(p_u)=0$}]}. 
    Then:


%First, for $u \in V(G)$ and $s \in V(S)$, we define $c_s(u, s)$ as the set of ancestors of $u$ mapped to $s$ in $m[u \rightarrow s]$.  In other words, if we remap $u$ to $s$, $c_s(u, s)$ is the set of vertices in the chain of $s$ that starts at $u$, going upwards. Also, we consider $r$ as the root of the $c_s(u, s)$.\\



    \begin{align*}
        \Lambda(u, s) &= \Lambda(p_u, s) - dist(s, m(u)) +  i_{m}(p_u) + dist(s, s) - i_{m[u \rightarrow s]}(p_u) +\lambda(u,s)\\
        &= \Lambda(p_u, s) - dist(s, m(u)) +\lambda(u,s)\\
    \end{align*}
    %   {\Delta L(u, s) &= NL(r, s) - NL(r, m(r))         &= \sum_{v \in c_s(u, s)} \Bigl(dist(s, m(v_l)) + dist(s, m(v_r))  &- dist(m(v), m(v_l)) - dist(m(v), m(v_r)) - i_{m(v)} \Bigl) &+ dist(s , m(u_l)) +  dist(s , m(u_r)) -  dist(m(u), m(u_l)) - dist(m(u), m(u_r)) - i_{m(u)}.}
    %\ml{[ML: I think it's close to that, but I tried it with a tree in which every node is a speciation.  If we have a path of spec and remap a node in the middle, some losses are not counted correctly.  I suggest you try your formula on that.  I think it has to do with specs that become dups.]}
\end{proof}

%Always one of $dist(s, m(v_l))$ or $dist(s, m(v_r))$ will be 0 because it is one of the sides on the chain, which means $m(v_l)$ or $m(v_r)$ is mapped to $s$ then the distance between $s$ and $s$ is 0.\\

We can compute distance between two species in time $O(h(S))$ \rk{(or in $O(1)$ with a defined data structure?)} \ml{[ML: yes, we can assume that any distance in $S$ can be obtained in time $O(1)$, either by precomuting every distance, or there's also a way if we assume constant time lca queries]}. Then, for every $u \in V(G)$ can be computed in time $O(|V(G)| h(S))$.  \\

%Also, $c_s(u, s)$ same as $c_m(u, s)$ can be computed for every $u \in V(G)$ and $s \succ m(u)$ in time $O(|V(G)| h(S))$.





\newpage

\section{Analyze reconciliation trees}
I've analyzed a simulation with our own simulated gene trees and noted points that prevent the greedy algorithm from acting like true reconciliation. In the \ref{sim} table, you can see the information of these simulated gene trees. As you can see in true reconciliation we only have one duplication whereas in lca and greedy we have 3 duplication heights which is not good so we are looking for the reason.\\

\begin{table}[hbt!]
\centering
\resizebox{1.05\columnwidth}{!}{%
\begin{tabular}{lll|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|l|}{\textbf{D(lca-simphy)}} & \multicolumn{1}{l|}{\textbf{D(greedy-simphy)}} & \textbf{D(ultragreedy-simphy)} & \textbf{C(simphy)} & \textbf{DH(simphy)} & \textbf{NBL(simphy)} & \textbf{C(lca)}         & \textbf{DH(lca)}         & \textbf{NBL(lca)}         \\ \hline
\multicolumn{1}{|l|}{22}                     & \multicolumn{1}{l|}{22}                        & 22                             & 460                & 1                   & 455                  & 442                     & 3                        & 427                       \\ \hline
\textbf{}                                    & \textbf{}                                      & \textbf{}                      & \textbf{C(greedy)} & \textbf{DH(greedy)} & \textbf{NBL(greedy)} & \textbf{C(ultragreedy)} & \textbf{DH(ultragreedy)} & \textbf{NBL(ultragreedy)} \\ \cline{4-9} 
                                             &                                                &                                & 442                & 3                   & 427                  & 442                     & 3                        & 427                       \\ \cline{4-9} 
\end{tabular}
}
\caption{\label{sim}Info about simulated gene trees.}
\end{table}

First of all, there are cases where lca and greedy do not infer any duplications due to losses, for example in \ref{fig:rec1}, but these cases are not easy to handle.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.85\textwidth]{rec1.PNG}
    \caption{True reconciliation has 1 duplication in species 17, but lca and greedy have no duplication, they just infer it as a speciation in species 16. The outer gene tree is the true reconciliation and the middle tree represents the lca and the inner tree is the greedy reconciliation.}
    \label{fig:rec1}
\end{figure}

Moreover, the above doesn't actually change the height of the duplication because it doesn't infer any duplications, so we'll look at cases that change the duplication.\\

In figure \ref{fig:rec2} it's an example when lca and greedy infer the duplication in species 16 while the duplication in true reconciliation is in species 17. In this case greedy tries to remap the duplication to species 17 but when it looks at other gene trees, there are other gene trees that have the same situation (lca and greedy have duplication in species 16 instead of 17) so by remapping 16 to 17 duplication height doesn't change, so there is no point for greedy algorithm to remap it (if it remap it just increase number of losses).\\

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.85\textwidth]{rec2.PNG}
    \caption{True reconciliation has 1 duplication in species 17, but lca and greedy have one duplication in species 16. The outer gene tree is the true reconciliation and the middle tree represents the lca and the inner tree is the greedy reconciliation.}
    \label{fig:rec2}
\end{figure}

In another example (figure \ref{fig:rec3}) with the same reason as above lca and greedy remap the duplication to species 15 instaed of 17.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.85\textwidth]{rec3.PNG}
    \caption{True reconciliation has 1 duplication in species 17, but lca and greedy have one duplication in species 15. The outer gene tree is the true reconciliation and the middle tree represents the lca and the inner tree is the greedy reconciliation.}
    \label{fig:rec3}
\end{figure}

Interestingly, among 100 gene trees, there are only 2 trees where lca infers duplication in species 15 instead of 17. Also, if you remember greedy uses lca mapping as initial step, and greedy progresses the nodes one by one. When it tries to remap one of them, it notices that already in another gene tree we have a duplication in species 15, so there is no point for greedy to remap it to 17.\\

Solution: Add a feature that can remap some nodes at the same time? Or use another mapping for the initial step?


\section{Gene trees Simulator}
We define a simulator that takes the species tree as input and generates specified numbers of gene trees based on the species tree and some rates. The purpose of this simulation is to simulate segmental duplication.
\subsection{Duplication}
\begin{itemize}
    \item {Branch Length.} the format of species tree is newick and the length of the branch determines the probability of duplication in that branch. For example, if the branch length for node $x$ is 1, we have a repeat at node $x$.

    \item {Rate.} When a node becomes a duplicate, we have two new branches between the duplicate node and the left and right copies that we need to decide on their length (probability of duplication). Rate specifies this length, by dividing the length of the branch of the duplicate node by Rate, we will have the length of the new branches. Just a special case when the rate is 0, the length of the new branch is considered as 0.
\end{itemize}

\subsection{Loss}
After applying duplication to the gene tree, we will apply loss to them. For this purpose we count the number of leaves that are mapped to a specific species. If we called this number $n$ for species $s$, we can have different loss rates for the leaves mapped to $s$.

\begin{itemize}
    \item {Fix Rate.} at this rate, we have a fixed rate ( $(n-1)/n$ ) for all leaves mapped to $s$ , and it will not change even after each leaf is removed.

    \item {Decrease Numerator.} in this rate, we start with the fix rate ( $(n-1)/n$ ) and after removing a leaf, we decrement the numerator by 1 ($(n-1-1)/n$) and so on.

    \item {Decrease Numerator/Denominator} in this rate, we start with the fix rate ( $(n-1)/n$ ) and after removing a leaf, we decrement the numerator and denominator by 1 ($(n-1-1)/(n-1)$) and so on.
\end{itemize}

\subsection{Finalizing gene trees}
In the last step, we need to remove some branches because after duplication actions and losses, some internal nodes may become leaves, which we need to remove. Also, we may have some internal nodes with only one child that we need to remove as well.

\end{document}
